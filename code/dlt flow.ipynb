{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75363816-26fa-456d-9fd2-e4d5f9acfbb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import date_format, current_timestamp,col,cast,when,sum,round,trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce51f97e-a7d8-439a-b633-fd7ff8d556eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "container = spark.conf.get(\"Container\")\n",
    "storageAccount = spark.conf.get(\"StorageAccount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fd73531-b058-4b6b-80d2-786643edd376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "location = f'abfss://{container}@{storageAccount}.dfs.core.windows.net'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44ae0fe5-9cd6-4f5a-a936-0ffdfbb3be6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### BRONZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36c6450f-3071-42dd-b6f3-7b817b8a11ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dlt.table(\n",
    "    name ='bronze_price_state',\n",
    "    schema=\"\"\"\n",
    "    state_id STRING NOT NULL PRIMARY KEY,\n",
    "    state_label STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING\n",
    "    \"\"\"\n",
    ")\n",
    "def state():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/price_state/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bd3226c-3729-454c-a53c-540903596f0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_price_substate',\n",
    "    schema=\"\"\"\n",
    "    substate_id STRING NOT NULL PRIMARY KEY,\n",
    "    substate_label STRING,\n",
    "    state_id STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_state_id FOREIGN KEY (state_id) REFERENCES gsynergy.default.bronze_price_state(state_id)\n",
    "    \"\"\"\n",
    ")\n",
    "def substate():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/price_substate/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5334510f-a9a5-4f8c-a0fc-5620f7f14194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_hldy',\n",
    "    schema=\"\"\"\n",
    "    hldy_id STRING NOT NULL PRIMARY KEY,\n",
    "    hldy_label STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING\n",
    "    \"\"\"\n",
    ")\n",
    "def hldy():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/hldy/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f904b467-d34e-4991-b03e-86d601369caf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_invstatus',\n",
    "    schema=\"\"\"\n",
    "    code_id STRING NOT NULL PRIMARY KEY,\n",
    "    code_label STRING,\n",
    "    bckt_id STRING,\n",
    "    bckt_label STRING,\n",
    "    ownrshp_id STRING,\n",
    "    ownrshp_label STRING, \n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING\n",
    "    \"\"\"\n",
    ")\n",
    "def hldy():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/invstatus/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c57fe5e3-3616-4986-a6c0-1ba3d6a62e88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_clnd',\n",
    "    schema=\"\"\"\n",
    "    fscldt_id STRING NOT NULL PRIMARY KEY,\n",
    "    fscldt_label STRING,\n",
    "    fsclwk_id STRING,\n",
    "    fsclwk_label STRING,\n",
    "    fsclmth_id STRING,\n",
    "    fsclmth_label STRING,\n",
    "    fsclqrtr_id STRING,\n",
    "    fsclqrtr_label STRING,\n",
    "    fsclyr_id STRING,\n",
    "    fsclyr_label STRING,\n",
    "    ssn_id STRING,\n",
    "    ssn_label STRING,\n",
    "    ly_fscldt_id STRING,\n",
    "    lly_fscldt_id STRING,\n",
    "    fscldow STRING,\n",
    "    fscldom STRING,\n",
    "    fscldoq STRING,\n",
    "    fscldoy STRING,\n",
    "    fsclwoy STRING,\n",
    "    fsclmoy STRING, \n",
    "    fsclqoy STRING,\n",
    "    date STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING\n",
    "    \"\"\"\n",
    ")\n",
    "def clnd():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/clnd/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0319c228-7e80-40e5-88da-51e747c6d63e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_invloc',\n",
    "    schema=\"\"\"\n",
    "    loc STRING NOT NULL PRIMARY KEY,\n",
    "    loc_label STRING,\n",
    "    loctype STRING,\n",
    "    loctype_label STRING, \n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING\n",
    "    \"\"\"\n",
    ")\n",
    "def invloc():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/invloc/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89fb23d2-8e91-4488-8d41-6afff147a7ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_region',\n",
    "    schema=\"\"\"\n",
    "    rgn INTEGER NOT NULL PRIMARY KEY,\n",
    "    rgn_label STRING, \n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING\n",
    "    \"\"\"\n",
    ")\n",
    "def region():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/region/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70feeead-ea4c-4b9b-a84c-076c4986d519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_district',\n",
    "    schema=\"\"\"\n",
    "    dstr INTEGER NOT NULL PRIMARY KEY,\n",
    "    dstr_label STRING, \n",
    "    rgn INTEGER ,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_rgn_id FOREIGN KEY (rgn) REFERENCES gsynergy.default.bronze_region(rgn)\n",
    "    \"\"\"\n",
    ")\n",
    "def district():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/district/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d0400e3-f34c-4153-a08e-b44b80bd0de3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_street',\n",
    "    schema=\"\"\"\n",
    "    str INTEGER NOT NULL PRIMARY KEY,\n",
    "    str_label STRING, \n",
    "    dstr INTEGER ,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_dstr_id FOREIGN KEY (dstr) REFERENCES gsynergy.default.bronze_district(dstr)\n",
    "    \"\"\"\n",
    ")\n",
    "def street():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/street/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2cac463-97c4-4424-b305-1844c6aa3e12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_dept',\n",
    "    schema=\"\"\"\n",
    "    dept_id INTEGER NOT NULL PRIMARY KEY,\n",
    "    dept_label STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING\n",
    "    \"\"\"\n",
    ")\n",
    "def dept():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/dept/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34eb6196-82a2-410b-92af-92dd760f8dd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_cat',\n",
    "    schema=\"\"\"\n",
    "    cat_id INTEGER NOT NULL PRIMARY KEY,\n",
    "    cat_label STRING,\n",
    "    dept_id INTEGER,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_dept_id FOREIGN KEY (dept_id) REFERENCES gsynergy.default.bronze_dept(dept_id)\n",
    "    \"\"\"\n",
    ")\n",
    "def cat():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/catg/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c1bf2ce-0c3c-4378-98be-8403a987d64f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_subcat',\n",
    "    schema=\"\"\"\n",
    "    subcat_id INTEGER NOT NULL PRIMARY KEY,\n",
    "    subcat_label STRING,\n",
    "    cat_id INTEGER,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_cat_id FOREIGN KEY (cat_id) REFERENCES gsynergy.default.bronze_cat(cat_id)\n",
    "    \"\"\"\n",
    ")\n",
    "def subcat():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/subCatg/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e5719cd-7e25-4648-a776-aee288665131",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_styl',\n",
    "    schema=\"\"\"\n",
    "    styl_id STRING NOT NULL PRIMARY KEY,\n",
    "    styl_label STRING,\n",
    "    subcat_id INTEGER,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_subcat_id FOREIGN KEY (subcat_id) REFERENCES gsynergy.default.bronze_subcat(subcat_id)\n",
    "    \"\"\"\n",
    ")\n",
    "def styl():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/style/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20f89c38-01aa-427e-9974-8bb477316526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_stylclr',\n",
    "    schema=\"\"\"\n",
    "    stylclr_id STRING NOT NULL PRIMARY KEY,\n",
    "    stylclr_label STRING,\n",
    "    styl_id STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_styl_id FOREIGN KEY (styl_id) REFERENCES gsynergy.default.bronze_styl(styl_id)\n",
    "    \"\"\"\n",
    ")\n",
    "def stylclr():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/stylclr/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "139cbca6-f1dd-47b4-a841-511aac896274",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_product',\n",
    "    schema=\"\"\"\n",
    "    sku_id STRING NOT NULL PRIMARY KEY,\n",
    "    sku_label STRING,\n",
    "    stylclr_id STRING,\n",
    "    issvc BOOLEAN,\n",
    "    isasmbly BOOLEAN,\n",
    "    isnfs BOOLEAN,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_stylclr_id FOREIGN KEY (stylclr_id) REFERENCES gsynergy.default.bronze_stylclr(stylclr_id)\n",
    "    \"\"\"\n",
    ")\n",
    "def product():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/product/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fe3d1dc-9a51-46ce-9a65-d2a41e999ad5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_chnl',\n",
    "    schema=\"\"\"\n",
    "    chnl_id STRING NOT NULL PRIMARY KEY,\n",
    "    chnl_label STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING\n",
    "    \"\"\"\n",
    ")\n",
    "def chnl():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/chnl/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e96a6a78-2519-4224-80e7-8c99eea6fc03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_subchnl',\n",
    "    schema=\"\"\"\n",
    "    subchnl_id STRING NOT NULL PRIMARY KEY,\n",
    "    subchnl_label STRING,\n",
    "    chnl_id STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_chnl_id FOREIGN KEY (chnl_id) REFERENCES gsynergy.default.bronze_chnl(chnl_id)\n",
    "    \"\"\"\n",
    ")\n",
    "def subchnl():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/subchnl/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b862d9c-c506-4364-ab1c-bbae8569cc37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_site',\n",
    "    schema=\"\"\"\n",
    "    site_id STRING NOT NULL PRIMARY KEY,\n",
    "    site_label STRING,\n",
    "    subchnl_id STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_subchnl_id FOREIGN KEY (subchnl_id) REFERENCES gsynergy.default.bronze_subchnl(subchnl_id)\n",
    "    \"\"\"\n",
    ")\n",
    "def site():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/site/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6295a480-99f2-40da-9d09-896b14fff404",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_transactions',\n",
    "    schema=\"\"\"\n",
    "    order_id STRING NOT NULL PRIMARY KEY,\n",
    "    line_id STRING,\n",
    "    type STRING,\n",
    "    dt STRING,\n",
    "    pos_site_id STRING NOT NULL,\n",
    "    sku_id STRING NOT NULL,\n",
    "    fscldt_id STRING NOT NULL,\n",
    "    price_substate_id STRING,\n",
    "    sales_units STRING,\n",
    "    sales_dollars STRING,\n",
    "    discount_dollars STRING,\n",
    "    original_order_id STRING,\n",
    "    original_line_id STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_pos_site_id FOREIGN KEY (pos_site_id) REFERENCES gsynergy.default.bronze_site(site_id),\n",
    "    CONSTRAINT fk_sku_id1 FOREIGN KEY (sku_id) REFERENCES gsynergy.default.bronze_product(sku_id),\n",
    "    CONSTRAINT fk_fscldt_id2 FOREIGN KEY (fscldt_id) REFERENCES gsynergy.default.bronze_clnd(fscldt_id),\n",
    "    CONSTRAINT fk_price_substate_id FOREIGN KEY (price_substate_id) REFERENCES gsynergy.default.bronze_price_substate(substate_id)\n",
    "    \"\"\"\n",
    ")\n",
    "def transactions():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/transactions/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82cb7b8f-0989-4fc0-8187-9652996541af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name ='bronze_averagecosts',\n",
    "    schema=\"\"\"\n",
    "    fscldt_id STRING NOT NULL,\n",
    "    sku_id STRING NOT NULL,\n",
    "    average_unit_standardcost STRING,\n",
    "    average_unit_landedcost STRING,\n",
    "    _rescued_data STRING,\n",
    "    file_processed_date STRING,\n",
    "    CONSTRAINT fk_fscldt_id1 FOREIGN KEY (fscldt_id) REFERENCES gsynergy.default.bronze_clnd(fscldt_id),\n",
    "    CONSTRAINT fk_sku_id2 FOREIGN KEY (sku_id) REFERENCES gsynergy.default.bronze_product(sku_id)\n",
    "    \"\"\"\n",
    ")\n",
    "def averagecosts():\n",
    "    df = spark.readStream.format(\"cloudFiles\")\\\n",
    "      .option(\"cloudFiles.format\", \"parquet\")\\\n",
    "      .load(f\"{location}/averagecosts/\")\\\n",
    "      .withColumn('file_processed_date',date_format(current_timestamp(),'yyyy-MM-dd HH:mm:ss'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c1d10e8-233c-431e-803a-a5a7e0a00bff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SILVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfce12a9-2636-4602-8bc8-166a17a7b3a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_hldy = {\"valid_hldy_code\": \"hldy_id IS NOT NULL AND hldy_label IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_hldy'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_hldy)\n",
    "def hldy():\n",
    "\tdf = spark.readStream.table('LIVE.bronze_hldy')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0dc170bd-fa08-47c9-8d3c-9069207493b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_status = {\"valid_invstatus\": \"code_id IS NOT NULL AND bckt_id IS NOT NULL AND ownrshp_id IS NOT NULL\"}\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_invstatus'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_status)\n",
    "def invstatus():\n",
    "\tdf = spark.readStream.table('LIVE.bronze_invstatus')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44365a7f-7f55-4c06-8e18-ba38a4680e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_loc = {\"valid_invloc\": \"loc IS NOT NULL AND loctype IS NOT NULL\"}\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_invloc'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_loc)\n",
    "def invloc():\n",
    "\tdf = spark.readStream.table('LIVE.bronze_invloc')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54332c07-5ab1-44c4-b3e8-5a73db8c4515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "\tname = 'silver_clnd'\n",
    ")\n",
    "def clnd():\n",
    "\tdf = spark.readStream.table('LIVE.bronze_clnd').withColumnRenamed('fscldt_id','clnd_fscldt_id').drop('_rescued_data').drop('file_processed_date')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01e85583-7935-4976-8226-ac5bf74cdaeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_str = {\"strcode\": \"str IS NOT NULL AND dstr IS NOT NULL AND str > 0 \"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_street'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_str)\n",
    "def street():\n",
    "\tdf = spark.readStream.table('LIVE.bronze_street')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5e58fca-d374-461c-a56f-952b2d9bb24b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_rgn = {\"rgncode\": \"rgn IS NOT NULL AND rgn_label IS NOT NULL\"}\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_region'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_rgn)\n",
    "def region():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_region')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34b2624a-6f70-4050-ac07-33b701905e5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_dstr = {\"dstrcode\": \"dstr IS NOT NULL AND rgn IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_district'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_dstr)\n",
    "def district():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_district')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5310f2d-af77-4089-bd7d-72245acb1756",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_units = {\"standardcost\": \"average_unit_standardcost >= 0\", \"landedcost\": \"average_unit_landedcost >=0\",\"valid_id\":\"fscldt_id IS NOT NULL AND sku_id IS NOT NULL\"}\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_averagecosts'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_units)\n",
    "def averagecosts():\n",
    "\tdf = spark.readStream.table('LIVE.bronze_averagecosts')\\\n",
    "     .withColumn('average_unit_standardcost',col('average_unit_standardcost').cast('double'))\\\n",
    "     .withColumn('average_unit_landedcost',col('average_unit_landedcost').cast('double'))\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d24c1a01-5349-4c87-9ca5-c8ba597bffa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_trans = {\"units\": \"sales_units >= 0\", \"sales\": \"sales_dollars >=0\", \"discount\": \"discount_dollars >=0\",\"type\":\"type is not NULL AND type!=''\",\"valid_id\":\"pos_site_id IS NOT NULL AND sku_id IS NOT NULL AND fscldt_id IS NOT NULL AND price_substate_id IS NOT NULL\"}\n",
    "\t\n",
    "\t\n",
    "@dlt.table(\n",
    "\tname = 'silver_transactions'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_trans)\n",
    "def transactions():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_transactions')\\\n",
    "\t.withColumn('discount_dollars',col('discount_dollars').cast('double'))\\\n",
    "\t.withColumn('sales_dollars',col('sales_dollars').cast('double'))\\\n",
    "\t.withColumn('order_id',col('order_id').cast('long'))\\\n",
    "\t.withColumn('line_id',col('line_id').cast('integer'))\\\n",
    "\t.withColumn('original_order_id',col('original_order_id').cast('long'))\\\n",
    "\t.withColumn('original_line_id',col('original_line_id').cast('integer'))\\\n",
    "\t.withColumn('sales_units',col('sales_units').cast('integer'))\\\n",
    "\t.withColumn('type',when(col('type') =='','NONTYPE').when( col('type') == None, 'NONTYPE').otherwise(col('type')))\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e60491ae-51ad-4131-a892-43c99a990b27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_price_state = {\"state\": \"state_id IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_price_state'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_price_state)\n",
    "def price_state():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_price_state')\n",
    "\treturn df\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8168e620-f21d-445a-b243-f86042d29ad7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\t\n",
    "valid_price_substate = {\"substate\": \"substate_id IS NOT NULL AND state_id IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_price_substate'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_price_substate)\n",
    "def price_substate():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_price_substate')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dc824e8-8107-47ec-99e7-1b04ce809e03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_site = {\"site\": \"site_id IS NOT NULL\",\"subchnl\" : \"subchnl_id IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_site'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_site)\n",
    "def site():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_site')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a53bf481-2a18-49a5-914f-98c1739878ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_subchnl = {\"chnl\": \"chnl_id IS NOT NULL\",\"subchnl\" : \"subchnl_id IS NOT NULL\"}\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_subchnl'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_subchnl)\n",
    "def subchnl():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_subchnl')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cd8654a-3cfd-4685-8381-32fa7876185e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_chnl = {\"chnl\": \"chnl_id IS NOT NULL\"}\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_chnl'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_chnl)\n",
    "def chnl():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_chnl')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef45f287-0122-4763-8402-16a562b5a149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_dept = {\"dept\": \"dept_id IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_dept'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_dept)\n",
    "def dept():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_dept')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcf81d3a-8347-4a8e-a0af-8e3c5ec60a5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_cat = {\"cat\": \"cat_id IS NOT NULL AND dept_id IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_cat'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_cat)\n",
    "def cat():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_cat')\n",
    "\treturn df\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42650548-7673-4326-bf8c-66efeccc3238",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_subcat = {\"subcat\": \"cat_id IS NOT NULL AND subcat_id IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_subcat'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_subcat)\n",
    "def subcat():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_subcat')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f537db72-aedb-482a-8eca-9aec9db3e923",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_styl = {\"styl\": \"styl_id IS NOT NULL AND subcat_id IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_styl'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_styl)\n",
    "def styl():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_styl')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "372e5752-8e58-4c7f-a0a6-dfa770365c6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_stylclr = {\"stylclr\": \"styl_id IS NOT NULL AND stylclr_id IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_stylclr'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_stylclr)\n",
    "def stylclr():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_stylclr')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c89ae457-2711-4930-84b9-2a25dd2faa18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_prod = {\"prod\": \"sku_id IS NOT NULL AND stylclr_id IS NOT NULL\"}\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "\tname = 'silver_product'\n",
    ")\n",
    "@dlt.expect_all_or_drop(valid_prod)\n",
    "def prod():\n",
    "\tdf = spark.readStream\\\n",
    " \t.table('LIVE.bronze_product')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "944d150e-4ff0-4b20-9037-544f24e91b74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f0ae33b-abb1-42ab-b0cc-81047d18f5f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "\tname = 'gold_dim_possite'\n",
    ")\n",
    "def site():\n",
    "\tchnl_df = spark.read.table('LIVE.silver_chnl')\n",
    "\tsubchnl_df = spark.read.table('LIVE.silver_subchnl')\n",
    "\tsite_df = spark.read.table('LIVE.silver_site')\n",
    "\t\n",
    "\tdf = chnl_df.join(subchnl_df, chnl_df.chnl_id == subchnl_df.chnl_id, 'left')\\\n",
    "     .join(site_df, subchnl_df.subchnl_id == site_df.subchnl_id, 'left')\\\n",
    "     .select(chnl_df['chnl_id'],subchnl_df['subchnl_id'],site_df['site_id'],site_df['site_label'])\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db9e4fa0-d227-40e5-bba4-bca26fbb3fd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "\tname = 'gold_dim_state'\n",
    ")\n",
    "\n",
    "def state():\n",
    "\tprice_state_df = spark.read.table('LIVE.silver_price_state')\n",
    "\tprice_substate_df = spark.read.table('LIVE.silver_price_substate')\n",
    "\t\n",
    "\tdf = price_state_df.join(price_substate_df, price_state_df.state_id == price_substate_df.state_id, 'left')\\\n",
    "     .select(price_state_df['state_id'],price_substate_df['substate_id'],price_substate_df['substate_label'])\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f2bcf77-b44d-4043-a493-7d6f48cf98f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "\tname = 'gold_dim_product'\n",
    ")\n",
    "\n",
    "def product():\n",
    "\tproduct_df = spark.read.table('LIVE.silver_product')\n",
    "\tstyl_df = spark.read.table('LIVE.silver_styl')\n",
    "\tstylclr_df = spark.read.table('LIVE.silver_stylclr')\n",
    "\tsubcat_df = spark.read.table('LIVE.silver_subcat')\n",
    "\tcat_df = spark.read.table('LIVE.silver_cat')\n",
    "\tdept_df = spark.read.table('LIVE.silver_dept')\n",
    "\n",
    "\tdf = dept_df\\\n",
    "\t\t.join(cat_df, dept_df.dept_id == cat_df.dept_id, 'left')\\\n",
    "\t\t.join(subcat_df, cat_df.cat_id == subcat_df.cat_id, 'left')\\\n",
    "\t\t.join(styl_df, subcat_df.subcat_id == styl_df.subcat_id, 'left')\\\n",
    "\t\t.join(stylclr_df, styl_df.styl_id == stylclr_df.styl_id, 'left')\\\n",
    "\t\t.join(product_df, stylclr_df.stylclr_id == product_df.stylclr_id ,'left')\\\n",
    "\t\t.select(product_df['sku_id'].alias('prod_sku_id'), product_df['sku_label'], stylclr_df['stylclr_id'], styl_df['styl_id'], subcat_df['subcat_id'], cat_df['cat_id'], dept_df['dept_id'], product_df['issvc'], product_df['isasmbly'], product_df['isnfs'])\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ec05220-1d22-4525-ad64-fcc4a334c181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "\tname = 'gold_fact_transactions'\n",
    ")\n",
    "def transactions():\n",
    "\tproduct_df = spark.read.table('LIVE.gold_dim_product')\n",
    "\tclnd_df = spark.read.table('LIVE.gold_dim_clnd')\n",
    "\tsite_df = spark.read.table('LIVE.gold_dim_possite')\n",
    "\tstate_df = spark.read.table('LIVE.gold_dim_state')\n",
    "\ttrans_df = spark.read.table('LIVE.silver_transactions')\n",
    "\n",
    "\t#selectList = ['trans_df.*','product_df.sku_id','clnd_df.clnd_fscldt_id', 'site_df.site_id', 'state_df.substate_id','clnd_df._rescued_data','clnd_df.file_processed_date','trans_df.file_processed_date','trans_df._rescued_data']\n",
    " \n",
    "\tdf = trans_df\\\n",
    "\t\t.join(clnd_df, trim(trans_df.fscldt_id) == trim(clnd_df.clnd_fscldt_id), 'inner')\\\n",
    "\t\t.join(site_df, trim(site_df.site_id) == trim(trans_df.pos_site_id), 'left')\\\n",
    "\t\t.join(state_df, trim(state_df.substate_id) == trim(trans_df.price_substate_id), 'left')\\\n",
    "\t\t.join(product_df, trim(product_df.prod_sku_id) == trim(trans_df.sku_id), 'left')\\\n",
    "     # .drop(*dropList)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c82ed484-1eb0-4ffe-b026-63a35d464e34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "\tname = 'gold_dim_clnd'\n",
    ")\n",
    "def clnd():\n",
    "\tdf = spark.read.table('LIVE.silver_clnd')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0798c72-1225-4c71-8307-ce224bf072c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "\tname = 'gold_mview_weekly_sales'\n",
    ")\n",
    "\n",
    "def weekly_sales():\n",
    "\tclnd_df = spark.read.table('LIVE.gold_dim_clnd')\n",
    "\ttrans_df = spark.read.table('LIVE.gold_fact_transactions')\n",
    "\t\n",
    "\tdf = trans_df\\\n",
    "\t\t.join(clnd_df, trim(trans_df.fscldt_id) == trim(clnd_df.clnd_fscldt_id), 'inner')\\\n",
    "\t\t.groupBy(clnd_df['fsclwk_id'], trans_df['pos_site_id'], trans_df['price_substate_id'], trans_df['sku_id'],trans_df['type'])\\\n",
    "\t\t.agg(sum('sales_units').alias('total_sales_units')\\\n",
    "        ,sum('sales_dollars').alias('total_sales_dollars')\\\n",
    "        ,sum('discount_dollars').alias('total_discount_dollars'))\\\n",
    "        .select(clnd_df['fsclwk_id'],trans_df['type'], trans_df['sku_id'] , trans_df['pos_site_id'], trans_df['price_substate_id'], 'total_sales_units', round('total_sales_dollars',2).alias('total_sales_dollars'), round('total_discount_dollars',2).alias('total_discount_dollars'))\\\n",
    "        .orderBy('fsclwk_id')\n",
    "\treturn df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dlt flow",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
